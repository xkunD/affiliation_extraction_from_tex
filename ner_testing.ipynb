{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import spacy\n",
    "from spacy.training import Example\n",
    "\n",
    "# Load ROR dataset\n",
    "with open('ror.json', 'r') as f:\n",
    "    ror_data = json.load(f)\n",
    "\n",
    "# Extract institution names\n",
    "def extract_institution_names(ror_data):\n",
    "    institution_names = []\n",
    "    for entry in ror_data:\n",
    "        for name_entry in entry['names']:\n",
    "            institution_names.append(name_entry['value'])\n",
    "    return institution_names\n",
    "\n",
    "institution_names = extract_institution_names(ror_data)\n",
    "\n",
    "# Create training examples from the ROR institution names\n",
    "def create_training_data_from_ror(institution_names, num_samples=1000):\n",
    "    templates = [\n",
    "        \"{} is a leading research institute.\",\n",
    "        \"The work was done at {}.\",\n",
    "        \"The collaboration between {} and other universities is remarkable.\",\n",
    "        \"{} has been a pioneer in the field.\"\n",
    "    ]\n",
    "    \n",
    "    training_data = []\n",
    "    for _ in range(num_samples):\n",
    "        institution = random.choice(institution_names)\n",
    "        template = random.choice(templates)\n",
    "        text = template.format(institution)\n",
    "        entity_start = text.find(institution)\n",
    "        entity_end = entity_start + len(institution)\n",
    "        training_data.append((text, {\"entities\": [(entity_start, entity_end, \"INSTITUTION\")]}))\n",
    "    \n",
    "    return training_data\n",
    "\n",
    "# Create training data\n",
    "TRAIN_DATA = create_training_data_from_ror(institution_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('\\\\author{\\n    Danielle C. Maddix \\\\\\\\ Amazon Research \\\\\\\\ 2795 Augustine Dr. \\\\\\\\ Santa Clara, CA 95054 \\\\\\\\ \\texttt{dmmaddix@amazon.com} \\\\\\\\\\n    \\\\And\\n    Nadim Saad \\\\\\\\ Stanford University \\\\\\\\ 450 Serra Mall \\\\\\\\ Stanford, CA 94305 \\\\\\\\ \\texttt{nsaad31@stanford.edu} \\\\\\\\\\n    \\\\And\\n    Yuyang Wang \\\\\\\\ Amazon Research \\\\\\\\ 2795 Augustine Dr. \\\\\\\\ Santa Clara, CA 95054 \\\\\\\\ \\texttt{yuyawang@amazon.com} \\\\\\\\\\n    }', {'entities': [(35, 50, 'INSTITUTION'), (159, 178, 'INSTITUTION')]})]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-20 21:37:59.088428: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'nlp' has no attribute 'to_disk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 44\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Save the trained model to disk\u001b[39;00m\n\u001b[1;32m     43\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./trained_ner_model\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 44\u001b[0m \u001b[43mnlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_disk\u001b[49m(output_dir)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'nlp' has no attribute 'to_disk'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Modified function to handle multiple institutions\n",
    "def create_training_data_multiple_affiliations(templates, institutions):\n",
    "    training_data = []\n",
    "    \n",
    "    for template in templates:\n",
    "        text = template\n",
    "        entities = []\n",
    "        \n",
    "        # For each institution, find its position in the text\n",
    "        for institution in institutions:\n",
    "            entity_start = text.find(institution)\n",
    "            if entity_start != -1:  # Only include if found\n",
    "                entity_end = entity_start + len(institution)\n",
    "                entities.append((entity_start, entity_end, \"INSTITUTION\"))\n",
    "        \n",
    "        # Append the text and entity annotations if at least one institution was found\n",
    "        if entities:\n",
    "            training_data.append((text, {\"entities\": entities}))\n",
    "    \n",
    "    return training_data\n",
    "\n",
    "# Example usage\n",
    "templates = [\n",
    "    \"\"\"\\\\author{\n",
    "    Danielle C. Maddix \\\\\\\\ Amazon Research \\\\\\\\ 2795 Augustine Dr. \\\\\\\\ Santa Clara, CA 95054 \\\\\\\\ \\texttt{dmmaddix@amazon.com} \\\\\\\\\n",
    "    \\And\n",
    "    Nadim Saad \\\\\\\\ Stanford University \\\\\\\\ 450 Serra Mall \\\\\\\\ Stanford, CA 94305 \\\\\\\\ \\texttt{nsaad31@stanford.edu} \\\\\\\\\n",
    "    \\And\n",
    "    Yuyang Wang \\\\\\\\ Amazon Research \\\\\\\\ 2795 Augustine Dr. \\\\\\\\ Santa Clara, CA 95054 \\\\\\\\ \\texttt{yuyawang@amazon.com} \\\\\\\\\n",
    "    }\"\"\"\n",
    "]\n",
    "\n",
    "institutions = [\"Amazon Research\", \"Stanford University\"]\n",
    "\n",
    "# Generate training data\n",
    "training_data = create_training_data_multiple_affiliations(templates, institutions)\n",
    "print(training_data)\n",
    "\n",
    "import nlp\n",
    "# Save the trained model to disk\n",
    "output_dir = \"./trained_ner_model\"\n",
    "nlp.to_disk(output_dir)\n",
    "print(f\"Model saved to {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('\\\\author{\\n    Danielle C. Maddix \\\\\\\\ Amazon Research \\\\\\\\ 2795 Augustine Dr. \\\\\\\\ Santa Clara, CA 95054 \\\\\\\\ \\texttt{dmmaddix@amazon.com} \\\\\\\\\\n    \\\\And\\n    Nadim Saad \\\\\\\\ Stanford University \\\\\\\\ 450 Serra Mall \\\\\\\\ Stanford, CA 94305 \\\\\\\\ \\texttt{nsaad31@stanford.edu} \\\\\\\\\\n    \\\\And\\n    Yuyang Wang \\\\\\\\ Amazon Research \\\\\\\\ 2795 Augustine Dr. \\\\\\\\ Santa Clara, CA 95054 \\\\\\\\ \\texttt{yuyawang@amazon.com} \\\\\\\\\\n    }', {'entities': [(35, 50, 'INSTITUTION'), (159, 178, 'INSTITUTION')]})]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-18 01:28:15.715615: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'nlp' has no attribute 'to_disk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn [9], line 44\u001b[0m\n",
      "\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Save the trained model to disk\u001b[39;00m\n",
      "\u001b[1;32m     43\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./trained_ner_model\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m---> 44\u001b[0m \u001b[43mnlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_disk\u001b[49m(output_dir)\n",
      "\u001b[1;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'nlp' has no attribute 'to_disk'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Modified function to handle multiple institutions\n",
    "def create_training_data_multiple_affiliations(templates, institutions):\n",
    "    training_data = []\n",
    "    \n",
    "    for template in templates:\n",
    "        text = template\n",
    "        entities = []\n",
    "        \n",
    "        # For each institution, find its position in the text\n",
    "        for institution in institutions:\n",
    "            entity_start = text.find(institution)\n",
    "            if entity_start != -1:  # Only include if found\n",
    "                entity_end = entity_start + len(institution)\n",
    "                entities.append((entity_start, entity_end, \"INSTITUTION\"))\n",
    "        \n",
    "        # Append the text and entity annotations if at least one institution was found\n",
    "        if entities:\n",
    "            training_data.append((text, {\"entities\": entities}))\n",
    "    \n",
    "    return training_data\n",
    "\n",
    "# Example usage\n",
    "templates = [\n",
    "    \"\"\"\\\\author{\n",
    "    Danielle C. Maddix \\\\\\\\ Amazon Research \\\\\\\\ 2795 Augustine Dr. \\\\\\\\ Santa Clara, CA 95054 \\\\\\\\ \\texttt{dmmaddix@amazon.com} \\\\\\\\\n",
    "    \\And\n",
    "    Nadim Saad \\\\\\\\ Stanford University \\\\\\\\ 450 Serra Mall \\\\\\\\ Stanford, CA 94305 \\\\\\\\ \\texttt{nsaad31@stanford.edu} \\\\\\\\\n",
    "    \\And\n",
    "    Yuyang Wang \\\\\\\\ Amazon Research \\\\\\\\ 2795 Augustine Dr. \\\\\\\\ Santa Clara, CA 95054 \\\\\\\\ \\texttt{yuyawang@amazon.com} \\\\\\\\\n",
    "    }\"\"\"\n",
    "]\n",
    "\n",
    "institutions = [\"Amazon Research\", \"Stanford University\"]\n",
    "\n",
    "# Generate training data\n",
    "training_data = create_training_data_multiple_affiliations(templates, institutions)\n",
    "print(training_data)\n",
    "\n",
    "import nlp\n",
    "# Save the trained model to disk\n",
    "output_dir = \"./trained_ner_model\"\n",
    "nlp.to_disk(output_dir)\n",
    "print(f\"Model saved to {output_dir}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
